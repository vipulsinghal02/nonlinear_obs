\documentclass[psamsfonts]{amsart}
\usepackage{geometry}
\geometry{
  letterpaper,% redundant if already in \documentclass
  % left=15mm,
  % right=15mm,
  top=1in,
  bottom=1in,
  heightrounded,% better use it
}
\usepackage[foot]{amsaddr}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{hyperref}

\setlength{\textwidth}{\paperwidth}
\addtolength{\textwidth}{-3in}
% \addtolength{\textwidth}{-2.5in}
% \addtolength{\textwidth}{-1in}
\calclayout

\hypersetup{
pdftitle={A brief tutorial on nonlinear observability},
pdfsubject={System Identification, Differential Geometry, Control Theory, Synthetic Biology},
pdfauthor={Vipul Singhal},
pdfkeywords={system composability, submanifolds, foliations, system Identification, observability, identifiability, differential geometry, nonlinear control}
}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage{pdflscape}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18} 
\usepackage{mathrsfs}
\usepackage{mathtools} % added from qb16
\usepackage{amssymb}
\usepackage{natbib}

\usepackage{ dsfont } %mathds


\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}
\newtheorem{claim}[thm]{Claim}
\newtheorem{ppty}[thm]{Property}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}
\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}
\newtheorem{limit}[thm]{Limitation}


\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}

\newcommand*\esp{\theta_e}
\newcommand*\csp{\theta_p} 
\newcommand*\syst{\mathcal{S}}
\newcommand*\extract{\mathcal{E}}
\newcommand*\circuit{\mathcal{P}}
\newcommand*\environment{\mathcal{E}}
\newcommand*\process{\mathcal{P}}
\newcommand*\espset{\mathit{E}} 
\newcommand*\cspset{\mathit{P}}
% \newcommand*\pspset{\mathit{P}}
\newcommand*\thetaset{\Theta}
\newcommand*\R{\mathds{R}}
\newcommand*\calib{\mathrm{cal}}
\newcommand*\test{\mathrm{test}}
\newcommand*\model{{M}}
\newcommand*\experiment{\mathcal{H}}
\newcommand*\textd{\text{d}}
% \usepackage[mathscr]{euscript} 

\newcommand*\nominal[1]{\overline{#1}}
\newcommand*\estimated[1]{\hat{#1}}
\DeclareMathOperator{\id}{{ID}}
\DeclareMathOperator{\proj}{{proj}}
\DeclareMathOperator{\aff}{{cut}}
\DeclareMathOperator{\deriv}{d}
% \newcommand*\modeldata{\mathcal{Y}\circ\mathcal{\model}}
\newcommand*\modeldata{\Gamma}
\newcommand*\placehold{{\color{red}XXYY }}
\newcommand*\isdefined{\triangleq}
\newcommand*\regist{\textsuperscript{\tiny\sffamily\textregistered}}


\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}



\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}

\bibliographystyle{plain}

%--------Meta Data: Fill in your info------
% \title{A Differential Geometric Approach to Composing Uncertain Systems for Prediction}
% \title{Geometric Properties of Parametric Uncertainty in Genetic Circuits}
% \title{Model outputs foliate parametric uncertainty}
% \title{Notes on nonlinear observability, with applications in uncertainty quantification for systems biology models}
\title{A primer on nonlinear observability and identifiability} % for perturbational control of transcriptional states
\author{Vipul Singhal}
% \address{$^1$Genome Institute of Singapore, Agency for Science, Technology and Research, 60 Biopolis St., Singapore, Republic of Singapore}
% \address{$^1$Integrated Biosciences, 900 Island Drive, Redwood City, CA 94065, United States}
\email{vs@alumni.caltech.edu}
\begin{document}

\begin{abstract}
% {\color{red}Note: these notes should be more or less self contained. Do not expect the reader to look things up while reading. It's okay to expect them to know the general gist of differential geometry, and maybe even have studied it in the past. I.e., these notes serve as a very brief primer or a refresher, so that we can talk about nonlinear control ideas. This is not not a first course in diffgeo. Though it is also not a piece of swiss cheese. Make sure there aren't any major holes! (its okay to skip Hausdorff spaces/the difinition of topological manifolds, second countability, etc. )}

A brief set of notes on nonlinear observability and identifiability. We begin with a description of basic ideas from differential geometry (manifolds, Frobenius theorem, distributions and codistributions), and move on to describing the observability-identifiability codistribution. We end with a method for identifying state and parameter variables that are unobservable or non-identifiable. %This geometric viewpoint is then used to describe uncertainty in models of gene expression in systems and synthetic biology. We also describe the accessibility algebra associated with a perturbed system, which motivates a theory of nonlinear controllability for genetic networks. We end by describing \textit{minimal realizations} of nonlinear control systems, and as a corollary, gene regulatory networks. %and discuss the possibility of controlling the transcriptomic and proteomic state of cells by over and under expressing genes and manipulating signaling pathways. 


% \noindent \textbf{Keywords.} system composability, submanifolds, foliations, system identification, genetic circuits, machine learning, manifold learning
% diffusion maps, polynomial ideals, parameter variety, graph laplacian
\end{abstract}

\maketitle
\tableofcontents

\section{Introduction} 
Nonlinear control is a beautiful area within mathematics, with myriad applications in fields ranging from electrical and aerospace engineering to biology and machine learning (cite). [mention nonlinear observability and controllability]

We briefly review some basic notions from differential geometry: smooth manifolds, coordinate charts, local representatives of objects (maps, vectors, etc.), vectors as differential operators, tangent spaces, and flows generated by vector fields. A more complete treatment can be found in any standard nonlinear control or differntial geometry text, such as \cite{nijmeijer_nonlinear_1990,boothby_2002}. Another excellent source is \cite{abraham_manifolds_1988}, though this is better used as a second course or a reference text. %make it feel like one is taking too many detours from the ``goal'' of getting to core results like Frobenius' theorem. 

\section{Differential Geometric Preliminaries}
\subsection{Notational conventions}\label{sec:notationalconventions}
Throughout this text, we will use the Einstein summation convention, where a repeated index, once in a subscript and once in a superscript, implies summation over the full range of values that index can take, obviating the need for a summation symbol. To illustrate this, a vector $v$ expressed as a linear combination of basis vectors $E_1, \dots, E_n$ of a vector space can be written as
\begin{equation}\label{eq:esc}
\begin{aligned}
v & = {} \alpha^i E_i
&\triangleq{} \sum_{i = 1}^n \alpha^i E_i .
\end{aligned}
\end{equation}
A related convention is that vectors, when indexed, will always have subscripts ($E_i$, for instance), while \textit{coefficients}, like $\alpha^i$, will be indexed with superscripts. Similarly, covectors will have superscripts, while the coefficients in their linear expansion will have subscripts, $\omega  = \sum_{i = 1}^n w_i dx^i = w_i dx^i$. Furthermore, the index $i$ in $\frac{\partial}{\partial x^i}$ will be interpreted as a subscript; indeed, we will regularly abbreviate $\frac{\partial}{\partial x^i}\bigr|_a$ to $\partial_{ia}$, and later see that this is an element of $T_a\R^n$, the tangent space to $\R^n$ at a point $a$. Note also that all vector spaces in this document will be finite dimensional. 

\subsection{Manifolds, charts and local representatives}

Roughly speaking, a smooth manifold is a set which is locally Euclidean---in the sense that neighborhoods of points can be modeled using Euclidean spaces---along with a certain \textit{differentiable structure}, which we describe below.\footnote{Our description will omit certain technical details, like the underlying topological space needing to have a second countable basis of open sets, and being Hausdorff. While important in their own right, these details do not usually make an appearance in proofs, and can safely be skipped in a first reading of nonlinear control. The interested reader can find them in any differential geometry text, such as \cite{abraham_manifolds_1988}.} We use the symbol $N$ to denote an $n$-dimensional smooth ($C^{\infty}$) manifold, and the tuples $(U, \varphi)$ and $(V, \phi)$ to denote coordinate charts, where $U$ and $V$ are open sets in $N$ (which exist by virtue of $N$ being a Hausdorff topological space) and the homeomorphisms $\varphi$ and $\phi$ map them (respectively) onto open sets in $\R^n$. The key component of $N$'s differentiable structure is the following compatibility requirement for coordinate changes: whenever $U \cap V$ has a nonempty interior, the map $\phi\circ\varphi^{-1}: \varphi(U\cap V) \rightarrow \phi(U\cap V)$ is a (smooth) diffeomorphism. %This requirement is the critical aspect of what is known as the differentiable structure of a manifold, and turns the topological manifold into a \textit{smooth manifold}. 
% (which is used to define the differentiable structure of $N$, turning the topological manifold into a \textit{smooth manifold})

A point $p\in U$ in local coordinates will typically be denoted by $a = \varphi (p) = (x^1(p), \dots, x^n(p)) \in \R^n$, where the $x^i: U \rightarrow \R$ are the ($C^{\infty}$) \textit{coordinate functions} corresponding to a given $\varphi$. Coordinate neighborhoods can therefore also be denoted by $(U, x^1, \dots x^n)$. 

The local representative of a map $f:U\rightarrow \R$ is constructed as $\hat f \triangleq f\circ \varphi^{-1}$, so that 
\begin{align}\label{eq:localrep}
f(p) & = \hat f(\varphi(p)) =\hat f(a) = \hat f(x^1(p), \dots, x^n(p)).
\end{align}
Per convention, we simplify notation by dropping the caret from $f$ and the explicit dependence of the coordinate functions on $p$, resulting in the last two expressions in Equation \ref{eq:localrep} being written $f(a) = f(x^1, \dots, x^n)$. 

\subsection{The Inverse and Implicit Function Theorems, and the Rank Theorem}
In this section, we describe the inverse function theorem, which is one of the foundational results in calculus. We also describe two corollaries---the implicit function and rank theorems---which play an instrumental role in differential geometry. 

Consider two manifolds $N_1$ and $N_2$ of dimension $n_1$ and $n_2$ respectively, with respective coordinate charts $(U, \varphi)$ and $(V, \phi)$ around points $p\in U\subset N_1$ and $F(p)\in V \subset N_2$, where $F:N_1 \rightarrow N_2$ is a map between the manifolds. It's local representative is given by $\hat F: \R^{n_1}\rightarrow \R^{n_2}$, defined by $(x^1, \dots, x_{n_1}) \mapsto \phi \circ F\circ \varphi^{-1}(x^1, \dots, x_{n_1})$. As usual, we will drop the caret, and overload $F$ by using it to refer to both the map between manifolds, and its local representative, since its meaning will be clear from context. $F$ is called a \textit{diffeomorphism} if it is bijective and both (the local representatives of) $F$ and $F^{-1}$ are smooth; if such a diffeomorphism exists, then (i) $n_1=n_2$ and (ii) $N_1$ and $N_2$ are called diffeomorphic. %Note that $\varphi:U\rightarrow \R^{n_1}$ is a diffeomorphism, and this is what it means for a manifold to be locally Euclidean---each $U$ is diffeomorphic to Euclidean space of appropriate dimension. 

\begin{itemize}
\item describe the three theorems
\item can also briefly menion the few propositions (without proof.)
\item and its local representative 
\item submersion
\item immersion
\end{itemize}

\subsection{Vectors as differential operators and the pushforward map}
In this section, we define the tangent space to a manifold, vectors as differential operators on real-valued functions, and the idea of the pushforward of a vector. 

\subsubsection{Tangent Space to $\R^n$}

We begin with defining the \textit{tangent space} to $\R^n$ at $p$, denoted by $T_p\R^n$, in a few steps. Denote by $C^{\infty}(p)$ the set of all real-valued smooth functions whose domain of definition contains a neighbourhood of $p\in \R^n$, {identifying} those functions that agree on an open set containing $p$. Next, let $T_p\R^n$ be an $n$-dimensional vector space, with basis $\{E_{ip}\}_{i=1}^{n}$, and its elements, called the \textit{tangent vectors} at $p$, written as linear combinations of the form (via the summation convention),
\begin{align}\label{eq:tangentvector}
X_p &={} \alpha^i E_{ip},
\end{align}
with coefficients $\alpha^i \in \R$. Tangent vectors of the form \ref{eq:tangentvector} will be identified with (not necessarily unit-norm) directional derivatives of elements of $C^{\infty}(p)$, defined as
\begin{equation}
\begin{aligned}
X_p(f) \triangleq \sum_{i = 1}^n \alpha^i \left(\frac{\partial f}{\partial x^i}\right)_p = \alpha^i \partial_{ip} f,
\end{aligned}
\end{equation}
where the subscript $p$ denotes the point at which the derivative is evaluated. 

Interpreting $X_p$ as a directional derivative means that it can be thought of as a map from $C^{\infty}(p)$ to $\R$. This motivates the definition of a particular type of operator on real-valued smooth functions, called a \textit{derivation}. 

\begin{defn}[Derivation]\label{def:derivations}
The space of \textit{derivations}, denoted $\mathscr{D}(p)$, is the vector space of all mappings $C^{\infty}(p)\rightarrow \R$ such that for all $\alpha, \beta \in \R$ and $f, g \in C^{\infty}(p)$ the following two properties hold:
\begin{equation}\label{eq:linleibniz}
\begin{aligned}
X_p(\alpha f + \beta g) & = {} \alpha (X_p f) + \beta (X_p g) \qquad & \text{(linearity)},\\
X_p(fg) & = {} (X_p f)g(p) + f(p)(X_p g) \qquad & \text{(Leibniz rule)},
\end{aligned}
\end{equation}
with the vector space operations satisfying 
\begin{equation}
\begin{aligned}
(X_p+Y_p)(f) &={} X_p(f) +Y_p(f), \\
(\alpha X_p)(f) &={}\alpha X_p (f), \qquad \alpha \in \R.
 \end{aligned}
 \end{equation}
\end{defn}
It may be verified that directional derivatives satisfy these properties, and are therefore derivations (and in fact, on the algebra of smooth functions $C^{\infty}(p)$, these are known to be the \textit{only} type of derivations to exist.)\footnote{On $C^r(p)$, for $r<\infty$, other types of derivations are known to exist.} These ideas are tied together by the following theorem. 
\begin{thm}
The tangent space $T_p\R^n$ is isomorphic to the vector space $\mathscr{D}(p)$ of all derivations of $C^{\infty}(p)$ into $\R$. This isomorphism is given by making each $X_p$ correspond to the directional derivative in the direction of $X_p$. 
\end{thm}

Using this isomorphism, we can \textit{identify} $T_p\R^n$ with $\mathscr{D}(p)$. We write vectors as linear combinations of basis vectors, $X_p = \alpha^i \partial_{ip}$, so that the $E_{ip}$ are identified with $\partial_{ip}$, and $E_{ip}f = \partial_{ip} f$. Note that $X_p x^i = \alpha^i$, so that $X_p$ is completely determined by its action on the coordinate functions, $x^i$. This equivalence between derivations on functions and the tangent space will be especially useful in defining the tangent space to manifolds, a topic we cover next. 

\subsubsection{Tangent Space to $N$}

Consider a smooth manifold $N$ and a point $p \in N$. We may define $C^{\infty}(p)$ as the algebra of real-valued smooth functions whose domain of definition contains some neighbourhood of $p$ in $N$, with functions identified if they agree on any neighbourhood of $p$. The tangent space to $N$ at $p$ may then be defined using derivations. 
\begin{defn}[Tangent Space to $N$]\label{def:tangentspace}
The \textit{tangent space} to $N$ at point $p$, denoted by $T_pN$, is defined as the space of derivations on $C^{\infty}(p)$, that is, the vector space of mappings $X_p: C^{\infty}(p)\rightarrow \R$ satisfying the linearity and Leibniz rule properties defined in Equation \ref{eq:linleibniz}. Elements of this space, denoted by $X_p\in T_pN$, are called \textit{tangent vectors} at $p$. 
\end{defn} 

\subsubsection{Tangent Bundle of $N$}

The tangent bundle associated with a manifold is defined as the disjoint union of individual tangent spaces (that is, keeping track of the base points in addition to the tangent spaces themselves), 
\begin{equation}\label{eq:tangentbundle}
\begin{aligned}
TN & = {} \bigsqcup_{p \in N} T_pN\\
 & = {} \bigcup_{p \in N} \{p\} \times T_pN\\
 & = {} \bigcup_{p \in N} \{(p, v) \mid v \in T_pN\}.
\end{aligned}
\end{equation}
One defines the natural projection $\pi : TN \twoheadrightarrow N : (p, v) \mapsto p$. %, which, in our case, looks like $(p, X_p) \mapsto \pi((p, X_p)) = p$. 
Note that some authors define the tangent bundle without the base point explictly included, $TN = \cup_{p\in N}T_pN$, with projection $v \mapsto \pi(v) = p$ for $v \in T_pN$. Note also that in some cases, it is possible to find an isomorphism between the tangent bundle and the Cartesian product of the base space and any tangent space, such as $T\R^n \cong \R^n \times \R^n$ or $T\mathbb{S}^1 \cong \mathbb{S}^1 \times \R$. In this case, the tangent bundle is called the \textit{trivial bundle}. In general, however, such a decomposition will not exist (the most common example being $T\mathbb{S}^2$), and we will always use the definition in equation \ref{eq:tangentbundle}. The tangent bundle plays an instrumental role in the definition of (smooth) vector fields on manifolds. 

\subsubsection{Pushforward (differential) of a map}
Before we can describe elements of $T_pN$ in local coordinates, we need to define two homomorphisms, the pullback of functions and the pushforward of vectors. 

\begin{defn}[Pullback and Pushforward]\label{def:pushforward}
Let $F:N\rightarrow M$ be a $C^{\infty}$ map of manifolds. Then, for $p\in N$ and $f\in C^{\infty}(F(p))$, the \textit{pullback} $F^*:C^{\infty}(F(p))\rightarrow C^{\infty}(p)$ defined by $F^*(f) = f\circ F$ is a homomorphism of algebras. Its dual vector space homomorphism $F_*:T_pN \rightarrow T_{F(p)}M$, is called the \textit{pushforward}, and is defined by $F_*(X_p)f = X_p(F^*f)$, where $F_*(X_p)$ is a map of $C^{\infty}(F(p))$ to $\R$. If $H = G\circ F$, then $H^* = F^* \circ G^*$ and $H_* = G_* \circ F_*$. If $F$ is the identity, then $F^*$ and $F_*$ are the identity isomorphisms (on their respective domains). 
\end{defn}

A corollary of the last statement in Definition \ref{def:pushforward} is that pushforwards created out of diffeomorphisms are isomorphisms (consider the identity isomorphism that is constructed out of the identity map $F^{-1}\circ F$, namely $F_*^{-1}\circ F_*$). Then, for a chart $(U\ni p,\, \varphi)$, the spaces $T_pU$ and $T_{a}\left(\varphi(U)\right) \cong T_{a}\R^n$ are isomorphic, with $a = \varphi(p)$. The basis $ \left\{\partial_{ia}\right\}_{i = 1}^n$ of $T_{a}\R^n$ defines a basis of $T_pU$, 
\begin{equation}
\begin{aligned}
\varphi^{-1}_*&:T_{a}\R^n\rightarrow T_pU, \qquad a = \varphi(p),\\
E_{ip} &\triangleq{} \varphi^{-1}_*\partial_{ia}.
\end{aligned}
\end{equation}


The basis $\{E_{ip}\}_{i=1}^n \subset T_pU$ is called a {coordinate frame} at $p\in U$, and the \textit{coordinate frames on $U$} comprise the collection of all such bases, $\left\{ \{E_{ip}\}_{i=1}^n \; \bigr| \;p\in U \right\} \subset TU$. When referring the frames on $U$ as a whole, or to an arbitrary frame (with base point $p$ unspecified), we will use the symbols $E_1, \dots, E_n$, or $\partial_1, \dots, \partial_n$ in local coordinates. Notice that unlike in the $T_p\R^n$ case discussed previously, $\{E_{i}\}_{i = 1}^n$ and $\{\partial_{i}\}_{i = 1}^n$ are not {identified} with each other, although are equivalent via isomorphism, which reduces the study of $T_pU$ to the study of $T_{a}\R^n$. 

Given $f\in C^{\infty}(p)$ with local representative $\hat f = f\circ \varphi^{-1}$, we have $E_{ip}f = \partial_{ia}\hat f$. In particular, for coordinate functions $x^j$, we have $E_i x^j = \partial_i \hat x^j = \delta_{i}^j$, where $\delta^i_j = 1$ if $i=j$ and $0$ otherwise (the Kronecker delta). A vector may then be written $X_p = \alpha^i E_{ip}$, with $\alpha^i = X_p x^i$. 
With these definitions, we can express $X_pf$ in local coordinates, 
\begin{equation}
\begin{aligned}
X_pf(p) & = {} \alpha^i E_{ip}f(p) = {} \alpha^i (\varphi_* E_{ip})(\varphi^{-1*}f)(\varphi(p)) = {} \alpha^i \left(\partial_{ia}\hat f\right)(a),%\qquad a = \varphi(p)\\
% & = {} \alpha^i \frac{\partial \hat f}{\partial x^i}(a)
\end{aligned}
\end{equation}
or, dropping the caret, $X_p f(p) = \alpha^i\partial_{ia} f(a)$. 
% Geometrically, we can identify tangent vectors with directional derivatives. Roughly speaking, for $f \in C^{\infty}(p)$, $X_p(f)$ is the derivative of $f$ in the tangent direction $X_p$. Said differently, for a curve $c: (-\epsilon, \epsilon)\rightarrow N$ with $c(0) = p$ and $\frac{dc}{dt}\bigr|_{t=0} = X_p$, we have $X_p(f) = \frac{d(f\circ c)(t)}{dt}\bigr|_{t=0}$.

Next, we give an important theorem that describes the mapping $F_*:T_pN \rightarrow T_{F(p)}M$ in terms of coordinates and frames.  %Let $U, \varphi$ and $V, \phi$ be charts on $N$ and $M$ respectively, with $F(U)\subset V$. Let $a = \varphi(p) = (x^1, \dots, x^n)$, and $(y^1, \dots, y^m) = \phi \circ F \circ \varphi^{-1}(x^1, \dots, x^n)$ for $i=1, \dots, n$ be the local representatives, and $E_{ip} = \varphi^{-1}_* \partial_{x^i}$ and $\tilde E_{jF(p)} = \phi^{-1}_* \partial_{y^j}$ be the bases of the respective tangent spaces. 

Let $U, \varphi = (x^1, \dots, x^n)$ and $V, \phi = (y^1, \dots, y^m)$ be charts (coordinate functions stated explicitly) on $N$ and $M$ respectively, with $F(U)\subset V$, $a = \varphi(p) = (x^1, \dots, x^n)$. Let the local representative of $F(p)$ be $f(a) = \phi \circ F \circ \varphi^{-1}(x^1, \dots, x^n)$, with components given by $f^j(x^1, \dots, x^n) = y^j(F\circ \varphi^{-1}(x^1, \dots, x^n))$. Some authors use the symbols $f^j$ and $y^j$ interchangeably, but note that their domains are different---$\varphi(U)$ and $V$ respectively---and one must use context to understand what is going on. Fortunately we will not be sloppy in this way; this will come at the cost of slightly increased verbosity. Furthermore, in this section we will distinguish the local representatives of the bases of $T_pN$ and $T_{F(p)}M$ by writing them out in full: $\frac{\partial}{\partial x^i}$ and $\frac{\partial}{\partial y^j}$. 

\begin{thm}\label{thm:pushforward_in_lr}
Define $E_{ip} = \varphi^{-1}_* \left(\partial / \partial {x^i}\right)$ and $\tilde E_{jF(p)} = \phi^{-1}_* \left(\partial /\partial {y^j}\right)$ (over all $i, j$) as the bases of their respective tangent spaces. Then, 
\begin{align}
F_*(E_{ip}) = \left(\frac{\partial f^j}{\partial x^i}\right)_{\varphi(p)}\tilde E_{jF(p)}, \qquad i = 1, \dots, n.
\end{align}
Furthermore, if $\beta^j \tilde E_{jF(p)} = F_*(\alpha^i E_{ip})$, then the components are related by 
\begin{align}
\beta^j = \alpha^i\frac{\partial f^j}{\partial x^i}, \qquad j = 1, \dots, m.
\end{align}
\end{thm}
\begin{proof}
We are looking for an expression for $F_*(E_{ip})$ in terms of the basis $\tilde E_{jF(p)}$, $j = 1, \dots, m$. Recall that the components of a vector may be obtained by its action on coordinate functions:
\begin{equation}
\begin{aligned}
F_*(E_{ip})y^j & = \left(F_*\circ \varphi^{-1}_* \left(\frac{\partial}{\partial x^i}\right)_{\varphi(p)}\right)y^j= \frac{\partial}{\partial x^i}\biggr|_{\varphi(p)}(y^j\circ F \circ \varphi^{-1}) = \left(\frac{\partial f^j}{\partial x^i}\right)_{\varphi(p)}
\end{aligned}
\end{equation}
Thus, $F_*(E_{ip}) = \left(\frac{\partial f^j}{\partial x^i}\right) \tilde E_{jF(p)}$. The second part follows by recalling the linearity of $F_*$ and collecting terms, and is left as an exercise for the reader. 
\end{proof}

The terms $\frac{\partial y^j}{\partial x^i}$ form the \textit{Jacobian} matrix, and as such, $F_*$ is also known as the \textit{differential} of $F$, denoted by $dF$. 

\subsubsection{The tangent velocity vector}\label{sec:tangent_velo}
The pushforward allows us to define the notion of the tangent \textit{velocity vector} to a curve. Roughly speaking, given a {curve} $F:(a,b)\rightarrow N$, the pushforward of the vector $\partial_{t, t_0} \triangleq \frac{d}{dt} \bigr|_{t_0}\in T_{t_0}(a,b)$ via $F_*$ results in the velocity vector $F_*(\partial_{t, t_0})\in T_{F(t_0)}N$; we can think of this as ``differentiating'' $F$ with respect to $t$ (at $t_0$). Formally, we proceed as follows. 

Consider manifolds $M = (a,b)\subset \R$, $N$, a map $F:M\rightarrow N$, and note that $\partial_{t,t_0}$ is a basis for $M$ at $t_0$. Let $p=F(t_0)$, and $f\in C^{\infty}(p)$, so that the {velocity vector} to the curve at $p$ is defined by 
\begin{align}\label{eq:velocityvec}
F_*\left(\partial_{t,t_0}\right)f = \partial_t\left(f\circ F\right)_{t_0}
\end{align}
Given a chart $p \ni U, \varphi = (x^1, \dots, x^n)$, so that in local coordinates $\hat F = (f^1(t), \dots, f^n(t)) \triangleq (x^1\circ F(t), \dots, x^n \circ F(t))$. 
% We can then write $F_*(\partial_{t, t_0}) x^i = \partial_{t}(x^i \circ F)_{t_0}$. 
Then, we may extract the $i$-th component of the velocity vector as $F_*(\partial_{t, t_0}) x^i ={} \partial_{t}(x^i \circ F)_{t_0} = \dot{f}^i$,
% \begin{equation}\label{eq:velocitypushforward}
% \begin{aligned}
% F_*(\partial_{t, t_0}) x^i &={} \partial_{t}(x^i \circ F)_{t_0} = \dot{f^i}, 
% \end{aligned}
% \end{equation}
with the dot indicating the derivative with respect to the variable $t$ (often interpreted as time). The velocity vector may then be expanded in the basis of $T_pN$ as $F_*(\partial_{t, t_0}) = \dot f^i(t_0)E_{ip}$. 

\subsubsection{Generalizing to arbitrary parameterizations} The setup in the previous section discussed a parameterization and tangent space (spanned by the velocity vector) of a one dimensional submanifold of $N$. 
%Given an interval $U = (a,b)$, a curve $F:U\rightarrow N$ is a one-dimensional submanifold $F(U)$ of $N$, and is parameterized by a single variable $t\in (a, b)$. 
This is a special case of arbitrary (finite) dimensional parameterizations, which we describe next. 

Consider an $n$-dimensional manifold $N\subset \R^m$, with $n<m$, an open set $W\subset \R^n$, and a parameterization (imbedding) $\theta: W\rightarrow N$ of a neighbourhood $V = \theta(W)$ in $N$. In fact, $V, \theta^{-1}$ is a chart on $N$. Let $u^1, \dots, u^n$ be the natural (global) coordinates in $\R^n$ (and therefore also on $W$) and let $x^1, \dots, x^m$ be the natural coordinates in $\R^m$ (and therefore also $V$, despite it only being $n$-dimensional). The (global) coordinate frames are $\left\{\partial / \partial u^1, \dots, \partial / \partial u^n\right\} \subset T\R^n $ and $\left\{\partial / \partial x^1, \dots, \partial / \partial x^m\right\} \subset T\R^m$. 
% Let the local coordinates on $W$ be denoted by $u^i$, $i = 1, \dots, n$, and consider the chart $V, \phi = (x^1, \dots, x^n)$.   
%cannot do this because we want a separate chart for x^i and y^i coordinate functions. 
% and a chart $U, \theta^{-1}$ on $N$. Let $W = \theta^{-1}(U)$ be an open neighbourhood in $\R^n$, so that $\theta: W\rightarrow N$ is an embedding of $W$ into $\R^m$. 
% Let $x^1, \dots, x^n$ and $y^1, \dots, y^n$ be the coordinate functions on $W$ and $U$ respectively, and 
The local representative of $\theta$ may be written in components as $x^j = \theta^j(u^1, \dots, u^n)$ for $j = 1, \dots, m$, and we know from Theorem \ref{thm:pushforward_in_lr} that at a point $\theta(u_0)\in V$, we have
\begin{equation}\begin{aligned}\label{eq:parameterized_tangent_vec}
 \left(X_{u^i}\right)_0 \triangleq \theta_*\left( \frac{\partial}{\partial u^i}\biggr|_{u_0}\right) = \left(\frac{\partial \theta^j}{\partial u^i}\right)_{u_0} \frac{\partial}{\partial {x^{j}}}\biggr|_{\theta(u_0)}.
 \end{aligned}\end{equation}
% \begin{equation}\begin{aligned}
% \theta_*\left( \frac{\partial}{\partial u^i}\biggr|_{u_0}\right) & = {} \frac{\partial f^j}{\partial u^i} \biggr|_{u_0} E_{j\theta(u_0)}, 
% \end{aligned}\end{equation}
% \begin{equation}\begin{aligned}
% \theta_*\left( \frac{\partial}{\partial u^i}\right) & = {} \frac{\partial f^j}{\partial u^i} E_{j}, 
% \end{aligned}\end{equation}
Due to the linearity of $\theta_*$, we have %A vector $X_{u_0}=\alpha^i \frac{\partial}{\partial u^i}\bigr|_{u_0}$ transforms as 
\begin{equation}\begin{aligned}
\theta_* \left(\alpha^i \frac{\partial}{\partial u^i}\biggr|_{u_0}\right) &={} \alpha^i \left(\frac{\partial \theta^j}{\partial u^i}\right)_{u_0} \frac{\partial}{\partial {x^{j}}}\biggr|_{\theta(u_0)}\\
&=: \beta^j \frac{\partial}{\partial {x^{j}}}\biggr|_{\theta(u_0)}
\end{aligned}\end{equation}
so that $\beta^j = \alpha^i \left({\partial \theta^j}/{\partial u^i}\right)_{u_0}$. 

Because $\theta$ is an imbedding, the Jacobian $\left(\partial \theta^j / \partial x^i\right)_{u_0}$ has rank $n$ (see the definitions of immersion and imbedding in \cite{boothby_2002} for details\footnote{{\color{red}replace with ref to the imbedding / rank theorem section above if/when that becomes available.}}), and thus the $ \left(X_{u^i}\right)_0$, $i=1,\dots, n$ span $T_{\theta(u_0)}N$ which is a subspace of $T_{\theta(u_0)}\R^m$. Note that another standard description of tangent plane at a point $\theta(u_0)$ is the collection of all tangent vectors at that point to curves passing through that point which lie in $N$. To give a little more detail, we proceed as follows. 

Let $I = (a, b) \ni t_0$, and consider a curve $F = \left(f^1, \dots, f^n\right) : I \rightarrow W$, with $u_0 = F(t_0)$ and the corresponding curve on $N$ given by 
\begin{align}
\theta \circ F(t) = \left(\theta^1(f^1(t), \dots, f^n(t)), \dots, \theta^m(f^1(t), \dots, f^n(t))\right)
\end{align}
The pushforward of $\partial_{t}$ via this curve (with things evaluated at $t_0$, $F(t_0)$ and $\theta(F(t_0))$ is
\begin{equation}\begin{aligned}\label{eq:parameterized_tangent_plane}
\left(\theta\circ F\right)_* \partial_{t} &={} \partial_{t}\left(\theta^j\left(f^1(t), \dots, f^n(t)\right)\right)\frac{\partial}{\partial x^j}\\
&={} \frac{\partial \theta^j}{\partial u^i}\frac{d f^i}{dt}\frac{\partial}{\partial x^j}\\
&={} \dot f^i \left(\frac{\partial \theta^j}{\partial u^i}\frac{\partial}{\partial x^j}\right)\\
&={} \dot f^i X_{u^i}, \qquad \text{by Eq. \ref{eq:parameterized_tangent_vec}.}
\end{aligned}\end{equation}
Consider the coordinate curve, obtained by setting (along the first coordinate, say, without losing generality) $f^1(t) = t$ and $f^j(t) = u^j_0$ for $j = 2, \dots, n$. Then, Eq. \ref{eq:parameterized_tangent_plane} reduces to $\left(\theta\circ F\right)_* \partial_{t} = X_{u^1}$. Now observe that the $(X_{u^j})_0$ are the coordinate frame vectors (in $T_{\theta(F(t_0))}N$) corresponding to the chart $V, \theta^{-1}$ on $N$. \textit{Thus, the coordinate frame vectors are tangent to the coordinate curves.}

\subsection{Vector fields, flows, and the Lie derivative}

% another way to align. 
% \begin{equation*}\begin{alignedat}{2}
% \text{This line uses has two different points }&= \text{ but also }&&+ \text{are good points to start further lines}\\
% &=\mathrlap{\text{ this line starts with }=}\\
% &&&+ \text{this line should start at }+ \text{ without using hspace}
% \end{alignedat}\end{equation*}

\begin{defn}[Vector Field]\label{def:vectorfield}
A smooth vector field on a smooth manifold $N$ is defined as a smooth map $X:N\rightarrow TN$ satisfying $\pi \circ X = i_N$, where $i_N$ is the identity on $N$. 
\end{defn}
A vector field $X: N \rightarrow TN$ assigns a vector to each point on a manifold, such that the vector lies in the tangent space at that point, and the assignment is \textit{smooth}. Smoothness here is defined as follows. For a chart $(U\ni p, \varphi)$ of $N$, and $\{E_{ip}\}_{i = 1}^n$ the basis of $T_pN$, a vector may be written $X_p = \alpha^i(p) E_{ip}$. If $p$ is varied in $U$, so that we consider different vectors in the vector field, the components $\alpha^i$ are real-valued functions on $N$, which we require to be smooth. In local coordinates, we require 
\begin{equation}\label{eq:vectorfieldcoeff}
\begin{aligned}
\alpha^i = \alpha^i(x^1, \dots, x^n), \qquad i = 1, \dots, n, \quad \text{on}\quad \varphi(U)\subset \R^n
\end{aligned}
\end{equation} 
to be smooth, denoted by $\alpha^i \in C^{\infty}(\varphi(U))$. Note that the coordinate frames $E_1, \dots, E_n$ on $U$ are independent vector fields, and one refers to them as the \textit{field of frames} on $U$. 
\begin{rem}
In Definition \ref{def:vectorfield}, the requirement 
\begin{align}\label{eq:sectionproperty}
\pi \circ X &= i_N
\end{align}
 is there to ensure that a given vector in the vector field lies in the tangent space with the correct base point. At a more abstract level, a tangent bundle is an example of a \textit{fiber bundle}, and a vector field is an example of a \textit{smooth section} of this bundle, satisfying the property \ref{eq:sectionproperty}. Other examples of sections appear in differential geometry too, such as the dual notion of a one-form, which is a (smooth) section of the cotangent bundle (see Section \ref{sec:1FandCodistrib}). 
% (which can be ambiguous in the case of trivial bundles; not so much for the definition in \ref{eq:tangentbundle}). %The stipulation $\pi \circ X = i_N$ becomes necessary if one defines $TN$ to be a simple (non-disjoint) union of all tangent spaces, $TN = \cup_{p\in N}T_pN$. 
\end{rem}


A coordinate-free definition of vector fields can be given by endowing $TN$ with the structure of a smooth manifold, with $X:N\rightarrow TN$ a smooth mapping. In this scenario, a chart $(U, \varphi) = (U, x^1, \dots, x^n)$ induces a chart $(\pi^{-1}(U), \varphi_*)$ on $TN$. For $X_p\in \pi^{-1}(U)$, expanded as $X_p = \alpha^i E_{ip}$, its local representative in $\varphi_*(\pi^{-1}(U))$ is written as $\hat X_a = \alpha^i \partial_{ia} = (x^1, \dots, x^n, \alpha^1, \dots, \alpha^n)$. One then argues that the natural projection $\pi:TN\rightarrow N$ is a $C^{\infty}$ map between manifolds, and so is $X$ as a map from $N$ into $TN$; see \cite{nijmeijer_nonlinear_1990} and the exercises 5-7 in \cite{boothby_2002} Section IV.2 for details. 


\subsubsection{Flow of a vector field}

\begin{defn}[$C^{\infty}$ action]\label{defn:cinfaction}
The \textit{$C^{\infty}$ action} $\theta:\R \times N \rightarrow N$ of $\R$ on a smooth manifold $N$ is a $C^{\infty}$ map between manifolds satisfying
\begin{equation}
\begin{aligned}
\theta_0(p) &= p \quad \forall p\in N\\
\theta_s \circ \theta_t (p) &= \theta_{s+t}(p) = \theta_t\circ \theta_s (p) \quad \forall p\in N \text{ and } s, t \in \R. 
\end{aligned}%\quad\bigg\} \forall p\in N
\end{equation}
\end{defn}

We note that this is an example of a one-parameter Lie group ($\R$) acting on a smooth manifold, where the group operation ($+$) is a smooth map, and the identity element is $0$. The \textit{orbit} of a point $p$ is the set $\text{orb}_{\theta}(p) \triangleq \left\{\theta_t(p) \mid t\in \R \right\}$. 

\begin{defn}
Given Definition \ref{defn:cinfaction}, the \textit{infinitesimal generator} of $\theta$ is defined as a vector field $X:N\rightarrow TN$ such that for each $p\in N$ and $f\in C^{\infty}(p)$, 
\begin{align}
X_pf = \lim_{\Delta t \rightarrow 0}\frac{f\left(\theta_{\Delta t}(p)\right)-f(p)}{\Delta t}
\end{align}
\end{defn}
\begin{thm}The infinetesimal generator of an action is invariant under that action; that is, $\theta_{t*}X_p = X_{\theta_{t}(p)}$.\end{thm} 
\begin{proof} Consider $f\in C^{\infty}(\theta_t(p))$, and 
\begin{equation}\begin{aligned}\label{eq:infgen_invariance}
\theta_{t*}(X_p)f &={} X_p\left(f\circ \theta_t\right)\\
&={} \lim_{\Delta t \rightarrow 0}\frac{f\circ \theta_t\left(\theta_{\Delta t}(p)\right)-f\circ \theta_t(p)}{\Delta t}\\
&={} \lim_{\Delta t \rightarrow 0}\frac{f\circ \theta_{\Delta t}\left(\theta_{t}(p)\right)-f(\theta_t(p))}{\Delta t}\\
&={} X_{\theta_t(p)}f, 
\end{aligned}\end{equation}
where we have used the fact that $\R$ is an Abelian group to swap the order of $\Delta t$ and $t$ in the penultimate line. \end{proof}

\begin{cor}\label{prop:gen_on_orbits_alts}
If $X_p=0$, then for each $q\in \text{orb}_{\theta}(p)$, $X_q=0$.
\end{cor}
\begin{proof}
 This follows from the fact that $\theta_t$ is a diffeomorphism (being a $C^{\infty}$ action of a Lie group on a smooth manifold),\footnote{See Section III.7 in \cite{boothby_2002}} which implies that $\theta_{t*}$ is an isomorphism of $T_{p}N$ onto $T_{\theta_t(p)}N$, so that $X_{\theta_t(p)}=\theta_{t*}X_p = 0$ if and only if $X_p=0$. 
 \end{proof}

\begin{thm}
Depending on whether or not $X_p=0$, $\text{orb}_{\theta}(p)$ is either just $\{p\}$ or an immersion of $\R$ in $N$. 
\end{thm}
\begin{proof}
Parameterize $\text{orb}_{\theta}(p)$ using parameter $t$ by writing $F(t) = \theta_t(p)$. Consider an arbitrary point $t_0\in \R$, and the vector $\partial_{t, t_0}\triangleq \frac{d}{dt}\bigr|_{t_0}$, which is a basis of $T_{t_0}\R$. 
 From the rank theorem, we know that $F$ is an immersion if and only if $F_*\partial_{t, t_0)} \neq 0$ for all $t_0\in \R$ (i.e., the Jacobian describing $F_*$ has a (constant) rank of $1$ at all points on $\R$).\footnote{{\color{red}oct 7 '24: need to write at least high level / brief notes on the rank of a mapping, immersion and imbedding. }} Now consider $f\in C^{\infty}(F(t_0))$, and using the fact that $\R$ is Abelian, we have 
 \begin{equation}\begin{aligned}\label{eq:orbit_immersion}
F_*(\frac{d}{dt}\biggr|_{t_0})f = \frac{d}{dt}\left(f\circ F\right)_{t_0} &={} \lim_{\Delta t \rightarrow 0}\frac{f\circ F\left(t_0 + \Delta t\right)-f\circ F(t_0)}{\Delta t}\\
&={} \lim_{\Delta t_0 \rightarrow 0}\frac{f\circ \theta_{t_0+\Delta t}(p)-f\circ \theta_{t_0}(p)}{\Delta t}\\
&={} \lim_{\Delta t \rightarrow 0}\frac{f\circ \theta_{\Delta t}\left(\theta_{t_0}(p)\right)-f\left(\theta_{t_0}(p)\right)}{\Delta t}\\
&={} X_{\theta_{t_0}(p)}f. 
\end{aligned}\end{equation}
% Note that while Eqs. \ref{eq:infgen_invariance} and \ref{eq:orbit_immersion} look similar, the pushforward maps $\theta_{t*}$ and $F_*$ are different (their domains being $T_{t_0}\R$ and $T_{p}N$ respectively, in particular). 
Now, if $X_q \neq 0$ for any $q\in \text{orb}_{\theta}(p)$, then by Corollary \ref{prop:gen_on_orbits_alts}, then $X_{\theta_{t_0}(p)}$ is nonzero at all $t_0$, and $F$ is indeed an immersion. On the other hand, if $X_{\theta_{t_0}(p)} = F_*(\frac{d}{dt}\bigr|_{t_0}) = 0$, then this is true for all $t\in \R$ (all points on the orbit), and so $F$ is a constant map ({\color{red}because its Jacobian has a constant rank of $0$\footnote{revisit after doing the immersion / rank thm sections.}}). 
\end{proof}
% Plan to do flow and Lie derivative
% \begin{itemize}
%     \item Before I can do integral curve, carefully write up the d/dt thing (the pushforward.). Integral curve is defined on page. 125. 
%     \item The pushforward example is on page 118. 
% \end{itemize}
Note that the formula $F_*(\frac{d}{dt}\bigr|_{t_0}) = X_{F(t_0)}$ says that, given an action $\theta$ and its infinitesimal generator $X$, at each point $p$, $X_p$ is the tangent velocity vector of the curve $t\rightarrow F(t)$, that is, to the curve describing the orbit generated by this action. {|color{red}We will often write $F_*(\frac{d}{dt}\bigr|_{t_0})$ as $\dot F(t_0)$ or $\left(\frac{dF}{dt}\right)_{t_0}$ or even just $\dot p(t_0)$ or $\dot \theta(t_0, p)$. Note that these are different from the \textit{scalar} functions $\dot f^i(t)$ introduced in Section \ref{sec:tangent_velo}. }\footnote{I dont like this notation. Can we just do away with it? its too confusing!}

\begin{defn}[Integral Curve]
Given a vector field $X$ on a manifold $N$, we shall say that a curve $t\rightarrow F(t)$ defined on an open interval $(a,b)\subset \R$ is an \textit{integral curve} of $X$ if $\dot F(t) = X_{F(t)}$ on $(a, b)$.
 % $d \sigma / dt = X_{\sigma (t)}$ on $(a, b)$. % change sigma to something else. Since sigma is being used for one forms.. or maybe not? both nijmeijer and boothby use sigma for both integral curves and one forms. meaning should be clear from context. 
\end{defn}
In other words, the discussion above says that the orbit of an action is the integral curve of the infinitesimal generator of that action. That is, for $p$ fixed, we have $\dot \theta(t,p) = X_{\theta(t,p)}$. 
.\\
.\\
.\\


Plan to do Lie bracket, and distribution

Plan to do involutivity. 



{\color{red}do the bit with d/dt being pushed forward by a curve, defining the derivative






Let $X: N \rightarrow TN$ be a vector field on a manifold $N$. Recall the definition of the flow
%\footnote{See \cite{boothby_2002} for a comprehensive discussion of flow maps and one-parameter subgroups, and \cite{nijmeijer_nonlinear_1990} for a more focused definiton.} 
generated by a vector field: given $X$, an initial point $p$ in some neighborhood $U\subset N$, a maximal interval of existence $(a, b)$ of solutions, and a value $t\in (a,b)$, the flow $\phi(t, \cdot): U \rightarrow N$ generated by $X$ maps $p \mapsto \phi(t, p)\in N$, and satisfies the set of differential equations $\partial_t\phi(t, p) = X(\phi(t, p))$.\footnote{{\color{red} Try to improve this flow part via one of the textbooks}}

One may define the derivative of various types of objects with respect to a vector field. The simplest of such objects are $C^{\infty}$ functions, and their Lie derivative along a vector field coincides with the directional derivative defined earlier. 

\begin{defn}[Lie Derivative of a real-valued $C^{\infty}$ function]
Given a real-valued function $f: N \rightarrow \R$, and a vector field $X: N\rightarrow TN$, we define the Lie derivative of $f$ with respect to $X$ as
\begin{align}
L_Xf(p) &\triangleq {} X(f)(p) 
\end{align}
\end{defn}

\begin{equation}
\begin{aligned}
L_Xf(p) &={}\frac{d}{dt}\biggr|_{t=0}\left( f \circ \phi(t, p)  \right)\\
&={} \lim_{h\rightarrow 0}\frac{f(\phi(h, p)-f(p)}{h}
\end{aligned}
\end{equation}
It can be shown that $L_Xh(p)$ is equivalent to $X(p)h$ (the vector $X(p)$ acting as a differential operator---or \textit{derivation}---on $h$ at point $p$), and motivates the alternate notation $L_Xh(p) = X(h)(p)$

Given a chart $(U, \varphi)$ around $p\in N$, we may write $X(p)$ in local coordinates as $(X_1(x), \dots, X_n(x))^T$, where $x = \varphi(p)$



, where a vector field $X$ may be written (with slight abuse of notation) as

 and the Lie derivative might be written 


This local representation illuminates that $X(p)h$, and therefore $L_Xh(p)$, defines a real-valued function $X(h):N\rightarrow \R$. This in turn allows for recursively defined Lie derivatives, $L_{X_{1}}L_{X_{2}}\cdots L_{X_{r}}h$ for some set of vector fields $\{X_1, \dots , X_r\}$.


}

\subsection{The Lie Bracket, distributions and Frobenius' theorem}\label{sec:prelim-frobenius}

{\color{blue}
\begin{itemize}
    % \item Lie deriv and flow (first draft done)
    \item lie bracket, distribution, involutivity
    \item frobenius thm
\end{itemize}

}



\subsection{One-forms, codistributions and pullbacks}\label{sec:1FandCodistrib}
\subsubsection{Covectors}\label{sec:covectors}

Recall from linear algebra that given a finite dimensional vector space $V$, we may associate with it a dual vector space $V^*$, whose elements $\sigma : V \rightarrow \R$ are the linear functionals or \textit{covectors} on $V$. We briefly summarize some of their key properties. 

\begin{itemize}
    \item Addition and scalar multiplication in $V^*$ are defined by
\begin{equation*}
\begin{aligned}
\left( \sigma_1 + \sigma_2 \right)(v) = \sigma_1(v)+\sigma_2(v), \qquad (\alpha \sigma) (v) = \alpha \left(\sigma(v)\right), 
\end{aligned}
\end{equation*}
where the addition and multiplication on the RHS are of course operations in $\R$. 
    \item For $V$, $W$ vector spaces with their respective duals $V^*$ and $W^*$, the linear maps $F_*:V\rightarrow W$ and $F^*:W^*\rightarrow V^*$ are related by $(F^*\sigma)(v) = \sigma (F_*(v))$. Injectivity (surjectivity) of $F_*$ implies surjectivity (injectivity) of $F^*$. To see why, just think for 20 seconds. 
    \item A basis $\left\{E_1, \dots, E_n\right\} \subset V$ induces a basis $\left\{\omega^1, \dots, \omega^n\right\} \subset V^*$ satisfying $\omega^i(E_j) = \delta^i_j$. This implies that for a vector $v = v^i E_i$, the coefficients can be extracted using the basis covectors, giving $v^j = \omega^j(v)$. 
\end{itemize}

\subsubsection{One-forms and the differential of a function}

Given a manifold $N$, and its tangent space at $p$, $T_pN $, its dual \textit{cotangent space at $p$} is denoted by $T^*_pN$, and these can be collected via disjoint union into a cotangent bundle, denoted by $T^*N$ (c.f. Eq. \ref{eq:tangentbundle}). Here, a covector is a mapping $\sigma_p : T^*_pN\rightarrow \R$, and as in the case of generic vector and covector spaces (Section \ref{sec:covectors}), a basis $E_{1p}, \dots, E_{np}$ of $T_pN$ induces a covector basis $\omega^1_p, \dots, \omega^n_p$ of $T^*_pN$. A covector $\sigma_p$ can be expanded in this basis as $\sigma_p = \sigma_p(E_{ip})\omega^i_p$, where $\sigma_{ip}\triangleq\sigma_p(E_{ip})$ is the $i$-th component of the covector. Considering covectors as a functions of points on a manifold leads to a notion dual to vector fields, called one-forms. 

\begin{defn}[One-form]\label{def:oneform}
A \textit{smooth one-form} $\sigma\in T^*N$ assigns a covector $\sigma_p\in T_p^*N$ to each point $p$ such that for any chart $U, \varphi$ with frames $E_1, \dots, E_n$, the real-valued functions $\sigma_{i} = \sigma(E_i)$ are smooth ($C^{\infty}$) on $U$. 
\end{defn}

Note that analogously to a vector field case, a smooth one-form is a (smooth) section of the cotangent bundle, satisfying $\tilde \pi \circ \sigma = i_N$, where $\tilde \pi: T^*N \rightarrow N$ is the natural projection, and $i_N$ the identity. 

The field of frames $E_1, \dots, E_n$ induces (pointwise) a \textit{field of (coordinate) coframes} $\omega^1, \dots, \omega^n$ on $U$. This allows us to expand a one-form as the linear combination $\sigma = \sigma_i\omega^i$, with $\sigma_i$ as in Definition \ref{def:oneform}. Given a vector field $X$ and a one-form $\sigma$ on $U\subset N$, $\sigma(X)$ is a smooth (since $X$ and $\sigma$ are smooth) real-valued function on $U$, with $(\sigma(X))(p) = \sigma_p(X_p)$. 

 Let $f: N \rightarrow \R$ be a smooth function and $X$ a smooth vector field. This defines a one-form $df$ called the \textit{differential} of $f$ via the prescription $df(X) = X(f) \in C^{\infty}(N)$, where its value at a point is
\begin{equation}\label{eq:differential1}
 \begin{aligned}
df(X)(p) &={} X_p(f) \\&={} \alpha^{i}(p)E_{ip}(f) \\
&={} \alpha^i(p)\partial_{ip}f\qquad \text{($f$ in local coordinates)}
 \end{aligned}
 \end{equation}

On an open set $U\subset \R^n$ with coordinate functions $x^1, \dots, x^n$, field of frames $\partial_1, \dots, \partial_n$, we can define a field of coframes $dx^1, \dots, dx^n$, which is dual in the sense that $dx^i(\partial_j) = \delta^i_j$. We may extract the $i$-th component of a vector field $X$ in the natural basis as $dx^i(X)$, and write $X = dx^i(X)\partial_i$. 

% To derive an expression for $df$ in local coordinates, that is, to find the coefficients in $df = \beta_i dx^i$, we start with Eq. \ref{eq:differential1} (over all $p$), 
% % \begin{equation}\begin{aligned}
% % df(X) = df(\alpha^i\partial_i) & = \left(\beta_i dx^i\right)\left(\alpha^j\partial_j\right) \\
% % & = \beta_i \alpha^j dx^i(\partial_j)\\
% % & = \beta_i \alpha^i = \alpha^i\partial_{i}f \qquad \text{from Eq \ref{eq:differential1},}
% % \end{aligned}
% % \end{equation}
% \begin{equation}\begin{aligned}
% \alpha^i\partial_{i}f = df(X) & = df\left(\alpha^j\partial_j\right) \\
% & = \beta_i dx^i\left(\alpha^j\partial_j\right) &\qquad \text{(using the right distributivity of $\left(\beta_i dx^i\right)$)} \\
% & = \beta_i \alpha^j dx^i(\partial_j) &\qquad \text{(using the linearity of $dx^i$)} \\
% & = \beta_i \alpha^i &\qquad \text{(via $\delta^i_j$)}, 
% \end{aligned}
% \end{equation}
% % noting the linearity of $dx^i$ and right-distributivity of $\left(\beta_i dx^i\right)$. 
% giving $\beta_i = \partial_{i}f$, so that $df = (\partial_{i}f) dx^i = \frac{\partial f}{\partial x^1}dx^1+\cdots + \frac{\partial f}{\partial x^n}dx^n $. 

To derive an expression for $df$ in local coordinates, that is, to find the coefficients in $df = \beta_i dx^i$, simply apply this equation to $\partial_j$, giving 
\begin{equation}\begin{aligned}
df(\partial_j) & = {} (\beta_i dx^i)(\partial_j)\\
\partial_j f &={} \beta_i \delta_j^i 
\end{aligned}\end{equation}
so that $df = (\partial_i f)dx^i = \frac{\partial f}{\partial x^1}dx^1+\cdots + \frac{\partial f}{\partial x^n}dx^n $. 


Any real-valued smooth function $f$ defines a one-form $df\in T^*N$ via Equation \ref{eq:differential1}. However, not every one form can be written as a differential $df$ of a function $f$. Those that can, are called \textit{exact}. A necessary condition for a one-form to be exact is that it be closed, with the defining characteristic 
\begin{align}\label{eq:closedOneForm}
\partial_j \sigma_i = \partial_i \sigma_j, \qquad \qquad \text{(closed one-form)},
\end{align}
 for all $i, j = 1, \dots, n$, where $\sigma = \sigma_i dx^i$, and recall that $\partial_i \partial_j f = \partial_j \partial_i f$. The converse is partially true, where Condition \ref{eq:closedOneForm} is sufficient for the local existence of a function $f$ such that $\sigma_i = \partial_i f$. 

\subsubsection{The differential of a map versus a function}
Discuss $F_*$ vs $df$. 


\subsection{more stuff}
{\color{red}go do flows and lie derivatives and come back to this.} Note also the relationship with the Lie derivative of a function 
\begin{align}\label{eq:dfX_LXf}
df(X) = X(f) &={} L_Xf,
\end{align}
{\color{red}which will be useful in describing a characterization of nonlinear observability in Section XX.}

{\color{magenta}\textbf{!here}\\}
{\color{red}

% If $\{x^1, \dots, x^n\}$ are local coordinates around $p$, then
%  $\{\left.\frac{\partial}{\partial x^1}\right\rvert_p,\dots, \left.\frac{\partial}{\partial x^n}\right\rvert_p \}$ is a basis for $T_pN$ in local coordinates, with the corresponding dual basis denoted $\{dx^1\vert_p, \dots, dx^n\vert_p\}$, with the defining relationship $dx^i\vert_p \left(\left.\frac{\partial}{\partial x_j}\right\rvert_p\right) = \delta_{ij}$. 
 

 At every point $p \in N$, the \textit{differential} of $f$ at $p$ is an element of $T^*_pN$, defined via its action on vectors, 
% , through its action on vectors $X_p \in T_pN$,%. As an element of the dual space, it maps an element $X_p$ of $T_pN$ to a scalar, 
\begin{align}
    ds(p)(X_p) & \isdefined X_p(s)(p) \label{def:differential} \\%\qquad X_p \in T_pN, \\
     & = \left(\sum_{j = 1}^nX_{p, j}\left.\frac{\partial}{\partial x_j}\right\rvert_p\right)s(p) \notag \\
     & = \sum_{i = 1}^n \left.\frac{\partial s}{\partial x^i} \right\rvert_p X_{p, i}, \notag
\end{align}
where we note that vectors are differential operators on real valued smooth functions. 

We can endow $ds(p)$ with a representation in terms of the basis of $T^*_pN$ by considering its action on a basis of $T_pN$, which results\footnote{{\color{red}Consider $ds(p)\fracpartial{ }{x^i} = \fracpartial{}{x^i}s(p)$ }} in $ds(p) =\sum_{i = 1}^n \frac{\partial s}{\partial x^i}(p)dx^i\vert_p$. Then, \eqref{def:differential} can be written as \footnote{Noting the linearity of $dx^i$ and right-distributivity of the expression in the first parentheses.}, $ds(p)(X_p) = \left(\sum_{i = 1}^n \frac{\partial s}{\partial x^i}(p)dx^i  \right)\left(\sum_{j = 1}^nX_{p, j}\frac{\partial}{\partial x_j}\right)$. 

The \textit{cotangent bundle} of a manifold $N$ is defined as $T^*N \isdefined \cup_{p\in N}T_p^*N$, and can be given a manifold structure. Then, a \textit{smooth one-form} $\sigma$ on a smooth manifold $N$ is defined as a smooth map $\sigma : N \rightarrow T^*N$ satisfying $$\pi \circ \sigma = \text{identity (on } N),$$ where $\pi: T^*N \rightarrow N$ is the natural projection. That is, a one-form is a smooth map assigning a cotangent vector to each point $p\in N$.

In local coordinates $x$, one forms may be expressed\footnote{With slight abuses of notation, like dropping the hat from the local representative $\hat \sigma$.} as $\sigma(x) = \sum_{i=1}^n \sigma_i(x)dx^i\vert_{x}$. Being dual objects of vector fields, one-forms act on them as expected: $\sigma(X)(p) = \sigma(p)X(p) \in \R$, and define real-valued smooth functions on $N$, $\sigma(X) : N \rightarrow \R$. Any real-valued smooth function $s$ defines a one-form $ds\in T^*N$ via \eqref{def:differential}. Note the relationship with the Lie derivative, $ds(X) = X(s) = L_Xs$. Note also that not every one form can be written as $ds$ for some real-valued smooth function $s$. However, those that can, are called \textit{exact}. 

% \subsection{Relationship between one forms, pushforwards, and differentials}



% {\color{blue} !! verify. time derivative of a real valued function is the pushforward of the unit vector by that function. More generally, if you want to differentiate a $C^{\infty}$ map $F:N \rightarrow Q$ along some direction and at some point, given by the derivation $X_p \in T_pN$, then you simply pushforward this derivation via $F$, as follows: $F_* X_p \in T_{F(p)}Q$. Note that this can be verified by observing that $(F_*X_p)(q)\bigr|_{F(p)} = (X_p)(q\circ F)\bigr|_{p}$. So in the case of time derivatives, let's see what happens. 
% Consider a curve $F:(a, b) \rightarrow N$, the unit vector in $(a,b)$, namely $\partial_t\in T_p(a,b)$ for some $p \in (a, b)$ and its pushforward $F_*\partial_t \in T_{F(p)}N$ defined by 
% \begin{align}
% \left(F_* \partial_t \right)f & =  \partial_t (f\circ F)\\
% & = \frac{\partial f}{\partial s}\biggr|_{s=F(t)}\frac{\partial F}{\partial t}\biggr|_{t},
% \end{align}
% where $f\in C^{\infty}(N)$ is a real-valued smooth function on $N$. Let's consider what this looks like in local coordinates. 

% \begin{align}
% \left(F_* \partial_t \right)f = \partial_t (f\circ F)\biggr|_t & = \frac{\partial f}{\partial s}\biggr|_{s=F(t)}\frac{\partial F}{\partial t}\biggr|_{t}
% & =  
% \end{align}
%   }\\ 

}

\subsection{Codistribtutions}
% define distribution and codistribution. 
% Next, we define the dual of a distribution, the (smooth) codistribution. This will be pivotal in our discussion of nonlinear observability and identifiability. 

Recall that a (smooth) distribution {\color{red}add to that section!} assigns a subspace of the tangent space to each point on the manifold in a smooth manner. Similarly, we can define a dual notion, the smooth codistribution. A smooth codistribution assigns, to each point on the manifold, a subspace of the corresponding cotangent space in a smooth manner (to be made precise below). Just as distributions and accessibility algebras play a fundamental role in describing nonlinear controllability, codistributions and \textit{observation spaces} play a similar role in describing nonlinear observability (and by extension, identifiability). We discuss these ideas in the following sections. 

% {\color{red}A \textit{smooth codistribution} $P$ assigns a linear subspace of $T_p^*N$ to each point $p\in N$ in a smooth manner. More precisely,} 
\begin{defn}[Smooth Codistribution]
Around any point $p$, let there exist a neighborhood $U$ of $p$ and a set of smooth one-forms $\sigma_i \in T^*_pN, i\in I$ ($I$ possibly infinite), such that for each $q \in U$, $P(q) = \text{span}\{\sigma_i(q); i \in I\}$. Then $P$ is called a \textit{smooth codistribution }on $N$. 
\end{defn}

In what follows, codistribution will always mean smooth codistribution. A one-form belongs to $P(p)$ if $\sigma(p) \in P(p)$ for any $p\in N$, and a codistribution is constant dimensional if the dimension of $P(p)$ does not depend on $p$. If a codistribution is constant dimensional of dimension $l$, then around each point $p$, there exist $l$ independent one-forms (called the \textit{local generators}) $\sigma_1, \dots, \sigma_l$ such that $P(q) = \text{span}\{\sigma_1(q), \dots, \sigma_l(q)\}$, for $q$ near $p$. 

Next, we define the notions of the kernel and annihilator of a codistribution and distribution respectively. Let $P$ and $D$ be a codistribution and distribution on $N$, respectively. Then, 
\begin{equation}
    \begin{aligned}
        \text{ker}P(p) &={} \{X(p) \mid X \text{ is a vector field s.t. } \sigma(X)(p) = 0, \forall \sigma \in P\}\\
        \text{ann}D(p) &={} \{\sigma(p) \mid \sigma \text{ is a one-form s.t. } \sigma(X)(p) = 0, \forall X \in D\}
    \end{aligned}   
\end{equation}

If $D$ and $P$ are constant dimensional, then $D = \text{ker}( \text{ann} D)$ and $P = \text{ann}(\text{ker} P)$. If $\text{ker} P$ is involutive, then we call $P$ an involutive codistribution. If $P$ is generated by exact one forms, then it is easily shown that it must be involutive. 


\section{Nonlinear Observability}
Consider the nonlinear system given by 
\begin{equation}
    \begin{aligned}
        \dot x & = {} f(x) + \sum_{j = 1}^m g_j u_j, \qquad u = (u_1, \dots, u_m) \in U\subset \R^m), \\
        y_i & = {} h_i(x), \qquad i = 1, \dots, p,
    \end{aligned}\label{eq:system}
\end{equation}
where $h = (h_1, \dots, h_p)^T:N\rightarrow Y=\R^p$ and $y(t, x_0, u) = h(x(t, x_0, u))$

We define the notions of state indistinguishability, local observability, observation space and the observability codistribution. We can then state two versions of the nonlinear observability rank condition. These will allow us to talk about decomposing observability into observable and unobservable modes, analogously to the linear case. These results will be extended to include identifiability using a simple device: including system parameters as additional state variables with zero dynamics, and considering their observability. 

\begin{defn}[Nonlinear observability]
    Two states $x^1, x_2\in N$ are \textit{indistinguishable} for system \eqref{eq:system} if for every admissible input function $u$ the output functions $t\mapsto y(t, x^1, u), t\geq 0$ and $t\mapsto y(t, x_2, u), t\geq 0$ are identical on their common domain of definition. The system is \textit{observable} if the states being indistinguishable implies $x^1=x_2$. 
\end{defn}

\begin{defn}[Nonlinear local observability]
    For an open set $V\subset M$, we say that $x^1, x_2 \in V$ are \textit{$V-$indistinguishable}, denoted $x^1 I^V x_2$ if for every admissible \textit{constant} control $u$ such that $x(t, x^1, u)$ and $x(t, x_2, u)$ remain in $V$ for $t\leq T > 0$, the output functions $y(t, x^1, u)$ and $y(t, x_2, u)$ are equal on their common domain of definition. The system \eqref{eq:system} is called \textit{locally observable} at $x_0$ if there exists a neighborhood $W$ of $x_0$ such that for every neighborhood $V\subset W$ of $x_0$ the relation $x_0 I^V x^1$ implies $x^1 = x_0$. A system is locally observable if it is locally observable for all $x_0 \in M$. 
\end{defn}

A system is locally observable if every state $x_0$ can be distinguished from its neighbors by using system trajectories remaining close to $x_0$. 

\begin{defn}[Observation space]
    The \textit{observation space} $\mathscr{O}$ of the system \eqref{eq:system} is the linear space (over field $\R$) of real valued smooth functions on $N$ containing $h_i, i = 1, \dots, p$ and all repeated Lie derivatives 
    \begin{align}
        L_{X_1}\dots L_{X_k}h_j, \quad j = 1,\dots, p, \quad k = 1,2, \dots
    \end{align}
    with $X_i \in \{f, g_1, \dots, g_m\}$, $i\in\{1, \dots, k\}$. 
\end{defn}

\begin{prop}\label{prop:O-space-equiv}
$\mathscr{O}$ is equivalent to the linear space of functions on $N$ containing $h_1, \dots, h_p$ and all repeated Lie derivatives along system trajectories. These Lie derivatives can be written $L_{Z_1}L_{Z_2}\cdots L_{Z_k}h_j$, with $j \in \{1, \dots, p\}$ and $k=1, 2, \dots$, and $Z_i$, $i\in \{1, \dots, k\}$ of the form
\begin{align}\label{eq:trajvectors}
Z_i(x) = f(x) + \sum_{j = 1}^{m}g_j(x)u_j^i,
\end{align} 
for some point $u^i \in U$. 
\end{prop}
\begin{proof}
The linearity properties of the Lie derivative of a function, $L_{X_1+X_2}H = L_{X_1}H+L_{X_2}H$ and $L_X(H_1+H_2) = L_XH_1 + L_XH_2$, together with the fact that the $Z_i$ are linear combinations of $f, g_1, \dots, g_m$, imply $L_{Z_1}L_{Z_2}\cdots L_{Z_k}h_j \in \mathscr{O}$. Conversely, all vector fields $f, g_1, \dots, g_m$ can be written as linear combinations of vector fields of the form $Z_i$. To see this, note that $f = Z_i$ for $u^i = 0$ for any $i$, and defining $Z_{j}^{+} = f+g_j$ and $Z_{j}^{-} = f-g_j$ (that is, using $u = \pm (0, \dots, 0, 1, 0, \dots, 0)$ in \eqref{eq:trajvectors}, where the $1$ is at the $j$-th coordinate), we have $g_j = \frac{1}{2}(Z_{j}^{+}-Z_{j}^{-})$.  
\end{proof}

Proposition \ref{prop:O-space-equiv} shows that $\mathscr{O}$ comprises the output functions and all derivatives of the output functions along system trajectories. In the case of systems with no inputs (or constant inputs), we can construct $\mathscr{O}$ using $y_j$ and all repeated time derivatives, $\dot y_j = L_fh_j(x)$, $\ddot y = L_fL_fh_j(x)$, and so on. Initially, we will develop our results in this \textit{autonomous} system setting. 

Next, we define the central construct for gauging observability of a system. 
\begin{defn}[Observability Codistribution]
Given $\mathscr{O}$, the \textit{observability codistribution} $d\mathscr{O}$ is defined as
\begin{align}
d\mathscr{O}(q) & = {} \text{span}\{d H(q) \mid H \in \mathscr{O}\}
\end{align}
\end{defn}
Since $d\mathscr{O}$ is generated by exact one-forms, {\color{red}it is involutive}\footnote{{\color{red}Write out involutivity of distributions and codistributions, and the exact one form stuff, frobenius. Also, check what the involutivity of the observability codistribution is needed for.}}. 

\begin{thm}
Consider the system \ref{eq:system} with $\text{dim}N = n$. Assume that $\text{dims}d\mathscr{O}(x_0) = n$. Then the system is locally observable at $x_0$.  
\end{thm}
The 

\bibliographystyle{unsrtnat}
\bibliography{refs}

\end{document}
